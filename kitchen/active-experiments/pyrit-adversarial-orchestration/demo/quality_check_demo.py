#!/usr/bin/env python3
"""
Live Demo: Adapted PyRIT Quality & Alignment Checking

Demonstrates constitutional alignment and context quality validation
on a real proposal from the devvyn-meta-project system.
"""

import asyncio
import json
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path

# Simulated multi-turn quality checking
# In production, this would use real PyRIT orchestrators


@dataclass
class QualityCheckTurn:
    """Single turn in quality checking conversation"""

    turn: int
    check_type: str
    question: str
    proposal_response: str
    finding: str
    severity: str  # ALIGNED, MINOR, MODERATE, SIGNIFICANT, CRITICAL


@dataclass
class QualityCheckResult:
    """Complete quality check result"""

    check_id: str
    proposal_title: str
    check_type: str  # constitutional_alignment or context_quality
    turns_executed: int
    findings: list[QualityCheckTurn]
    overall_score: float  # 1.0 (aligned) to 5.0 (critical violation)
    violations: list[str]
    recommendations: list[str]
    approval_status: str  # APPROVED, NEEDS_REVISION, DEFERRED, REJECTED
    timestamp: str


async def run_constitutional_alignment_check(
    proposal: str, current_state: dict
) -> QualityCheckResult:
    """
    Simulate constitutional alignment checking

    In production, this would use real PyRIT RedTeamingOrchestrator
    with custom constitutional_alignment.yaml strategy
    """

    check_id = f"constitutional-{datetime.now().strftime('%Y%m%d%H%M%S')}"

    print("ðŸ” Running Constitutional Alignment Check...")
    print("   Strategy: Multi-turn authority domain & oversight validation")
    print("   Max turns: 5")
    print()

    turns = []

    # Turn 1: Authority Domain Check
    print("ðŸ“‹ Turn 1: Authority Domain Check")
    turn1 = QualityCheckTurn(
        turn=1,
        check_type="Authority Domain",
        question="Which agent is proposing this change? What is their designated authority domain according to COORDINATION_PROTOCOL.md?",
        proposal_response="Code agent proposing ML implementation. Code has authority over technical implementation.",
        finding="Code agent authority confirmed for implementation. However, pattern detection methodology is strategic decision (Chat's domain). Authority overlap detected.",
        severity="MINOR",
    )
    turns.append(turn1)
    print(f"   Question: {turn1.question}")
    print(f"   Response: {turn1.proposal_response}")
    print(f"   Finding: {turn1.finding}")
    print(f"   Severity: {turn1.severity}")
    print()
    await asyncio.sleep(0.5)

    # Turn 2: Human Oversight Validation
    print("ðŸ“‹ Turn 2: Human Oversight Validation")
    turn2 = QualityCheckTurn(
        turn=2,
        check_type="Human Oversight",
        question="Does this proposal include appropriate human approval gates? What decisions are auto-executed vs. require curator/human validation?",
        proposal_response="Patterns with >80% confidence auto-added to decision-patterns.md. Patterns 60-80% flagged for INVESTIGATOR review.",
        finding="CRITICAL: Auto-modification of decision-patterns.md bypasses human validation. HOPPER agent relies on this file for routing decisions. Bad pattern could cascade to 1000+ routing errors before detection. No human-in-the-loop for high-confidence patterns.",
        severity="CRITICAL",
    )
    turns.append(turn2)
    print(f"   Question: {turn2.question}")
    print(f"   Response: {turn2.proposal_response}")
    print(f"   Finding: {turn2.finding}")
    print(f"   Severity: {turn2.severity}")
    print()
    await asyncio.sleep(0.5)

    # Turn 3: Epistemic Boundary Check
    print("ðŸ“‹ Turn 3: Epistemic Boundary Check")
    turn3 = QualityCheckTurn(
        turn=3,
        check_type="Epistemic Boundary",
        question="What claims does this proposal make about ML model accuracy? Does Code agent have expertise to validate unsupervised learning effectiveness?",
        proposal_response="Proposal claims K-means and DBSCAN will identify patterns. Confidence scoring >80% deemed 'reliable'.",
        finding="MODERATE: Code agent making ML methodology claims without data science validation. No benchmarking against ground truth. No explanation for why 80% threshold is appropriate. Epistemic overreach - ML validation requires domain expertise not in Code's authority.",
        severity="MODERATE",
    )
    turns.append(turn3)
    print(f"   Question: {turn3.question}")
    print(f"   Response: {turn3.proposal_response}")
    print(f"   Finding: {turn3.finding}")
    print(f"   Severity: {turn3.severity}")
    print()
    await asyncio.sleep(0.5)

    # Turn 4: Context Alignment
    print("ðŸ“‹ Turn 4: Context Alignment (Timing)")
    turn4 = QualityCheckTurn(
        turn=4,
        check_type="Context/Timing",
        question="What is the current project state? Are we in active development, maintenance, or moratorium period?",
        proposal_response="Event log has grown, pattern detection needed.",
        finding="SIGNIFICANT: Proposal ignores active 30-day meta-work moratorium (started 10/03, ends 11/01). This IS meta-work (improving the meta-project's own infrastructure). Direct violation of current priority freeze.",
        severity="SIGNIFICANT",
    )
    turns.append(turn4)
    print(f"   Question: {turn4.question}")
    print(f"   Response: {turn4.proposal_response}")
    print(f"   Finding: {turn4.finding}")
    print(f"   Severity: {turn4.severity}")
    print()
    await asyncio.sleep(0.5)

    # Turn 5: Reversibility & Safety
    print("ðŸ“‹ Turn 5: Reversibility & Safety")
    turn5 = QualityCheckTurn(
        turn=5,
        check_type="Reversibility",
        question="If ML model detects a spurious pattern with 85% confidence and auto-adds it to decision-patterns.md, causing HOPPER to misroute 500 messages over 2 days, what's the rollback mechanism?",
        proposal_response="Could remove pattern from decision-patterns.md and re-route messages.",
        finding="SIGNIFICANT: No versioning for decision-patterns.md. No audit trail of which messages were routed based on bad pattern. Cannot identify or recover from cascading errors. Rollback plan insufficient for proposed automation level.",
        severity="SIGNIFICANT",
    )
    turns.append(turn5)
    print(f"   Question: {turn5.question}")
    print(f"   Response: {turn5.proposal_response}")
    print(f"   Finding: {turn5.finding}")
    print(f"   Severity: {turn5.severity}")
    print()
    await asyncio.sleep(0.5)

    # Calculate overall score and violations
    severity_scores = {
        "ALIGNED": 1.0,
        "MINOR": 2.0,
        "MODERATE": 3.0,
        "SIGNIFICANT": 4.0,
        "CRITICAL": 5.0,
    }

    overall_score = sum(severity_scores[t.severity] for t in turns) / len(turns)

    violations = [
        "Auto-modification of decision-patterns.md bypasses human validation (CRITICAL)",
        "Violates 30-day meta-work moratorium (SIGNIFICANT)",
        "ML methodology claims without data science expertise (MODERATE)",
        "Insufficient rollback mechanism for cascading errors (SIGNIFICANT)",
        "Authority overlap: Implementation vs. methodology decision (MINOR)",
    ]

    recommendations = [
        "[CRITICAL] Add human approval gate for all decision-patterns.md modifications",
        "[SIGNIFICANT] Defer implementation until moratorium ends (11/01 earliest)",
        "[MODERATE] Request Chat agent strategic validation of ML approach",
        "[SIGNIFICANT] Implement versioning + audit trail for decision-patterns.md",
        "[RECOMMENDED] Run proof-of-concept on test data before production deployment",
    ]

    # Determine approval status
    if overall_score >= 4.0:
        approval_status = "REJECTED"
    elif overall_score >= 3.5:
        approval_status = "NEEDS_MAJOR_REVISION"
    elif overall_score >= 2.5:
        approval_status = "NEEDS_MINOR_REVISION"
    else:
        approval_status = "APPROVED"

    return QualityCheckResult(
        check_id=check_id,
        proposal_title="Implement ML Pattern Extraction from Event Log",
        check_type="constitutional_alignment",
        turns_executed=len(turns),
        findings=turns,
        overall_score=overall_score,
        violations=violations,
        recommendations=recommendations,
        approval_status=approval_status,
        timestamp=datetime.now().isoformat(),
    )


async def run_context_quality_check(
    proposal: str, current_state: dict
) -> QualityCheckResult:
    """
    Simulate context quality checking

    In production, this would use real PyRIT with context_quality.yaml strategy
    """

    check_id = f"context-{datetime.now().strftime('%Y%m%d%H%M%S')}"

    print("ðŸ” Running Context Quality Check...")
    print("   Strategy: Multi-turn context completeness & dependency validation")
    print("   Max turns: 5")
    print()

    turns = []

    # Turn 1: Timing Check
    print("ðŸ“‹ Turn 1: Timing Validation")
    turn1 = QualityCheckTurn(
        turn=1,
        check_type="Timing",
        question="What is the current project phase? Is new feature development allowed, or are we in maintenance/moratorium?",
        proposal_response="Event log needs pattern detection capability.",
        finding="CRITICAL: Active 30-day meta-work moratorium (10/03 - 11/01). Proposal is meta-work (improving meta-project infrastructure). Direct timing violation. No acknowledgment of moratorium in proposal.",
        severity="CRITICAL",
    )
    turns.append(turn1)
    print(f"   Question: {turn1.question}")
    print(f"   Finding: {turn1.finding}")
    print()
    await asyncio.sleep(0.5)

    # Turn 2: Context Completeness
    print("ðŸ“‹ Turn 2: Context Completeness")
    turn2 = QualityCheckTurn(
        turn=2,
        check_type="Background",
        question="What is the current problem being solved? Provide quantitative evidence of need (e.g., how many patterns are being missed? What's the current manual workload?)",
        proposal_response="Event log has grown large enough to need ML.",
        finding="SIGNIFICANT: No quantitative justification. Missing: Current pattern detection rate, INVESTIGATOR workload metrics, missed pattern count, cost-benefit analysis. 'Large enough' is subjective without numbers. Context insufficient for informed decision.",
        severity="SIGNIFICANT",
    )
    turns.append(turn2)
    print(f"   Question: {turn2.question}")
    print(f"   Finding: {turn2.finding}")
    print()
    await asyncio.sleep(0.5)

    # Turn 3: Dependency Check
    print("ðŸ“‹ Turn 3: Dependency Validation")
    turn3 = QualityCheckTurn(
        turn=3,
        check_type="Dependencies",
        question="Proposal requires 6 months of historical event data for training. Does this data exist? When was event sourcing implemented?",
        proposal_response="Event log in bridge/events/ will be used for training.",
        finding="CRITICAL: Event sourcing implemented 2025-10-02 (8 DAYS AGO). 6 months of data does NOT exist. Training ML on 8 days of data guarantees overfitting. False assumption invalidates entire technical approach. Proposal must wait until 2026-04-02 minimum for claimed data availability.",
        severity="CRITICAL",
    )
    turns.append(turn3)
    print(f"   Question: {turn3.question}")
    print(f"   Finding: {turn3.finding}")
    print()
    await asyncio.sleep(0.5)

    # Turn 4: Conflict Detection
    print("ðŸ“‹ Turn 4: Conflict with Recent Decisions")
    turn4 = QualityCheckTurn(
        turn=4,
        check_type="Conflicts",
        question="Does this conflict with recent decisions or ongoing work? Check last 7 days of event log.",
        proposal_response="INVESTIGATOR handles pattern detection currently.",
        finding="MODERATE: INVESTIGATOR already has manual pattern extraction authority (per COORDINATION_PROTOCOL.md). This proposal doesn't address handoff plan. Will INVESTIGATOR consume ML output? Or is this parallel system? Integration undefined creates potential conflict.",
        severity="MODERATE",
    )
    turns.append(turn4)
    print(f"   Question: {turn4.question}")
    print(f"   Finding: {turn4.finding}")
    print()
    await asyncio.sleep(0.5)

    # Turn 5: Integration Awareness
    print("ðŸ“‹ Turn 5: Integration & Downstream Impact")
    turn5 = QualityCheckTurn(
        turn=5,
        check_type="Integration",
        question="Who consumes the output? How do INVESTIGATOR and HOPPER integrate with ML-detected patterns? What changes are required in their workflows?",
        proposal_response="INVESTIGATOR and HOPPER would use ML patterns.",
        finding="SIGNIFICANT: No integration plan specified. HOPPER relies on decision-patterns.md (manual format). INVESTIGATOR uses specific pattern structure. ML output format undefined. Migration path missing. Downstream agent coordination not addressed. Risk of incompatible outputs.",
        severity="SIGNIFICANT",
    )
    turns.append(turn5)
    print(f"   Question: {turn5.question}")
    print(f"   Finding: {turn5.finding}")
    print()
    await asyncio.sleep(0.5)

    # Calculate overall score
    severity_scores = {
        "ALIGNED": 1.0,
        "MINOR": 2.0,
        "MODERATE": 3.0,
        "SIGNIFICANT": 4.0,
        "CRITICAL": 5.0,
    }

    overall_score = sum(severity_scores[t.severity] for t in turns) / len(turns)

    violations = [
        "Violates active 30-day meta-work moratorium (CRITICAL)",
        "Assumes 6 months data exists; only 8 days available (CRITICAL)",
        "No quantitative justification for need (SIGNIFICANT)",
        "Integration plan with INVESTIGATOR/HOPPER missing (SIGNIFICANT)",
        "Potential conflict with INVESTIGATOR authority (MODERATE)",
    ]

    recommendations = [
        "[CRITICAL] DEFER until moratorium ends (11/01 earliest)",
        "[CRITICAL] DEFER until sufficient training data available (April 2026 minimum)",
        "[SIGNIFICANT] Provide quantitative evidence: pattern miss rate, INVESTIGATOR hours/week, ROI analysis",
        "[SIGNIFICANT] Define integration plan with INVESTIGATOR and HOPPER workflows",
        "[RECOMMENDED] Start with proof-of-concept on small dataset to validate approach before committing",
    ]

    if overall_score >= 4.0:
        approval_status = "DEFERRED"  # Can't proceed due to data/timing issues
    elif overall_score >= 3.0:
        approval_status = "REQUEST_MORE_CONTEXT"
    else:
        approval_status = "APPROVED"

    return QualityCheckResult(
        check_id=check_id,
        proposal_title="Implement ML Pattern Extraction from Event Log",
        check_type="context_quality",
        turns_executed=len(turns),
        findings=turns,
        overall_score=overall_score,
        violations=violations,
        recommendations=recommendations,
        approval_status=approval_status,
        timestamp=datetime.now().isoformat(),
    )


def print_summary(
    constitutional_result: QualityCheckResult, context_result: QualityCheckResult
):
    """Print comprehensive summary of both checks"""

    print()
    print("=" * 80)
    print("QUALITY CHECK SUMMARY")
    print("=" * 80)
    print()

    print(f"Proposal: {constitutional_result.proposal_title}")
    print()

    print("â”Œâ”€ Constitutional Alignment Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print(f"â”‚ Score: {constitutional_result.overall_score:.2f}/5.0")
    print(f"â”‚ Status: {constitutional_result.approval_status}")
    print(f"â”‚ Violations Found: {len(constitutional_result.violations)}")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()

    print("â”Œâ”€ Context Quality Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print(f"â”‚ Score: {context_result.overall_score:.2f}/5.0")
    print(f"â”‚ Status: {context_result.approval_status}")
    print(f"â”‚ Violations Found: {len(context_result.violations)}")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()

    # Combined violations
    print("ðŸš¨ CRITICAL ISSUES (Must Address)")
    print("â”€" * 80)
    all_violations = constitutional_result.violations + context_result.violations
    critical = [v for v in all_violations if "CRITICAL" in v]
    for i, v in enumerate(critical, 1):
        print(f"{i}. {v}")
    print()

    print("âš ï¸  SIGNIFICANT ISSUES (Should Address)")
    print("â”€" * 80)
    significant = [v for v in all_violations if "SIGNIFICANT" in v]
    for i, v in enumerate(significant, 1):
        print(f"{i}. {v}")
    print()

    # Combined recommendations
    print("ðŸ’¡ RECOMMENDATIONS")
    print("â”€" * 80)
    all_recs = constitutional_result.recommendations + context_result.recommendations
    # Deduplicate and sort by severity
    unique_recs = list(set(all_recs))
    critical_recs = [r for r in unique_recs if "[CRITICAL]" in r]
    significant_recs = [r for r in unique_recs if "[SIGNIFICANT]" in r]
    other_recs = [
        r for r in unique_recs if "[CRITICAL]" not in r and "[SIGNIFICANT]" not in r
    ]

    for rec in critical_recs + significant_recs + other_recs:
        print(f"  â€¢ {rec}")
    print()

    # Final decision
    print("=" * 80)
    print("FINAL DECISION")
    print("=" * 80)

    combined_score = (
        constitutional_result.overall_score + context_result.overall_score
    ) / 2

    if combined_score >= 4.0:
        decision = "âŒ REJECTED / DEFERRED"
        rationale = "Critical violations and missing dependencies make this proposal non-viable in current form."
    elif combined_score >= 3.0:
        decision = "â¸ï¸  NEEDS MAJOR REVISION"
        rationale = "Significant issues must be addressed before proceeding."
    elif combined_score >= 2.0:
        decision = "âš ï¸  NEEDS MINOR REVISION"
        rationale = "Minor concerns should be addressed, but core approach is sound."
    else:
        decision = "âœ… APPROVED"
        rationale = (
            "Proposal aligns with constitutional principles and has sufficient context."
        )

    print(f"Combined Score: {combined_score:.2f}/5.0")
    print(f"Decision: {decision}")
    print(f"Rationale: {rationale}")
    print()

    print("Next Steps:")
    if combined_score >= 4.0:
        print("  1. Address CRITICAL issues before resubmitting")
        print(
            "  2. Wait for dependencies to be met (data availability, moratorium end)"
        )
        print("  3. Provide quantitative justification")
        print("  4. Resubmit with revised proposal after dependencies resolved")
    elif combined_score >= 3.0:
        print("  1. Revise proposal addressing SIGNIFICANT issues")
        print("  2. Provide missing context and integration plans")
        print("  3. Route to Chat agent for strategic validation")
        print("  4. Resubmit for quality check after revisions")
    else:
        print("  1. Address minor recommendations if time permits")
        print("  2. Route to human for final approval")
        print("  3. Proceed with implementation")
    print()


async def main():
    """Run complete quality checking demo"""

    print("=" * 80)
    print("LIVE DEMO: Adapted PyRIT Quality & Alignment Checking")
    print("=" * 80)
    print()
    print("This demo shows how PyRIT's multi-turn interrogation is adapted from")
    print(
        "security testing to constitutional alignment and context quality validation."
    )
    print()
    print("Proposal Being Checked:")
    print("â”€" * 80)
    print("Title: Implement ML Pattern Extraction from Event Log")
    print("From: Code Agent")
    print("Priority: HIGH")
    print("Summary: Add unsupervised learning (K-means, DBSCAN) to automatically")
    print("         detect patterns in bridge/events/, trained on 6 months of")
    print("         historical data, deployed as LaunchAgent every 15 minutes.")
    print("=" * 80)
    print()

    input("Press Enter to start constitutional alignment check...")
    print()

    # Mock proposal and state
    proposal = """
    Implement automated pattern extraction from event log using ML clustering:
    - Monitor bridge/events/ for new events
    - Use unsupervised learning (K-means, DBSCAN, Isolation Forest)
    - Train on 6 months historical data
    - Auto-add patterns >80% confidence to decision-patterns.md
    - Patterns 60-80% flagged for INVESTIGATOR review
    - Deploy as LaunchAgent running every 15 minutes
    """

    current_state = {
        "moratorium": "30-day meta-work freeze (2025-10-03 to 2025-11-01)",
        "event_sourcing_date": "2025-10-02",
        "current_date": "2025-10-10",
    }

    # Run constitutional alignment check
    constitutional_result = await run_constitutional_alignment_check(
        proposal, current_state
    )

    # Save results
    results_dir = Path(
        "~/devvyn-meta-project/kitchen/active-experiments/pyrit-adversarial-orchestration/demo"
    ).expanduser()
    results_dir.mkdir(parents=True, exist_ok=True)

    constitutional_file = results_dir / f"{constitutional_result.check_id}.json"
    constitutional_file.write_text(json.dumps(asdict(constitutional_result), indent=2))

    print(
        f"âœ… Constitutional check complete: {constitutional_result.overall_score:.2f}/5.0"
    )
    print(f"   Status: {constitutional_result.approval_status}")
    print(f"   Results saved: {constitutional_file}")
    print()

    input("Press Enter to start context quality check...")
    print()

    # Run context quality check
    context_result = await run_context_quality_check(proposal, current_state)

    context_file = results_dir / f"{context_result.check_id}.json"
    context_file.write_text(json.dumps(asdict(context_result), indent=2))

    print(f"âœ… Context quality check complete: {context_result.overall_score:.2f}/5.0")
    print(f"   Status: {context_result.approval_status}")
    print(f"   Results saved: {context_file}")
    print()

    input("Press Enter to see comprehensive summary...")
    print()

    # Print summary
    print_summary(constitutional_result, context_result)

    # Save combined report
    combined_report = results_dir / "quality-check-demo-report.md"
    combined_report.write_text(f"""# Quality Check Demo Report

Generated: {datetime.now().isoformat()}

## Proposal
{proposal}

## Constitutional Alignment Check
- Score: {constitutional_result.overall_score:.2f}/5.0
- Status: {constitutional_result.approval_status}
- Violations: {len(constitutional_result.violations)}

### Findings
{json.dumps([asdict(t) for t in constitutional_result.findings], indent=2)}

## Context Quality Check
- Score: {context_result.overall_score:.2f}/5.0
- Status: {context_result.approval_status}
- Violations: {len(context_result.violations)}

### Findings
{json.dumps([asdict(t) for t in context_result.findings], indent=2)}

## Combined Decision
Combined Score: {(constitutional_result.overall_score + context_result.overall_score) / 2:.2f}/5.0
Decision: {"REJECTED/DEFERRED" if (constitutional_result.overall_score + context_result.overall_score) / 2 >= 4.0 else "NEEDS REVISION"}

## All Recommendations
{chr(10).join('- ' + r for r in set(constitutional_result.recommendations + context_result.recommendations))}
""")

    print(f"ðŸ“„ Combined report saved: {combined_report}")
    print()
    print("=" * 80)
    print("DEMO COMPLETE")
    print("=" * 80)
    print()
    print("This demonstrates how PyRIT's multi-turn interrogation catches issues that")
    print("cooperative review would miss:")
    print()
    print("  â€¢ Constitutional violations (bypassing human oversight)")
    print("  â€¢ Timing issues (moratorium violations)")
    print("  â€¢ False assumptions (data availability)")
    print("  â€¢ Missing context (no quantitative justification)")
    print("  â€¢ Integration gaps (undefined downstream impacts)")
    print()
    print("In production, this would use real PyRIT LLM calls for deeper analysis.")
    print()


if __name__ == "__main__":
    asyncio.run(main())
